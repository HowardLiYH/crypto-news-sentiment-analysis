{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connection_func import news_collecting\n",
    "from preprocessing_for_vader import preprocess_for_vader\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from model_vader import get_summed_polarity_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect News titles from 42 News Media and gather total over 1400 titles \n",
    "\n",
    "**News Medias include:** Cointelegraph, The Block, Decrypt, The Defiant, CoinDesk, Blockworks, Blockchain News, BeInCrypto, CNBC Blockchain News, Blockchain.com, Yahoo News Crypto Section, Techcrunch Blockchain Section, Economic Times, Forbes, Financial Times, Independent, The blockchain.com, The Conversation, Cryptonews, Wired, Fox Business, Crypto News Net, AP News, The Indian Express, The Time of India, BBC News, News Now, Blockchain Magazine, CCN, Washington Post, New York Time, Bezinga, Google News, New York Post, People.com, NBC News, Daily Mail, The Guardian, Wall Street Journal, Buzzfeed, MarketWatch, and Fortune\n",
    "\n",
    "**\n",
    "\n",
    "\n",
    "\n",
    "The following code takes around 50 secs to run depends on the network traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Connecting to Site No.1: Cointelegraph\n",
      "Total of 86 News Titles from Cointelegraph has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.2: Bbc\n",
      "Total of 28 News Titles from Bbc has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.3: Newyorktimes\n",
      "Total of 19 News Titles from Newyorktimes has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.4: Beincrypto\n",
      "Total of 16 News Titles from Beincrypto has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.5: The_Block\n",
      "Total of 32 News Titles from The_block has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.6: Nbc\n",
      "Total of 20 News Titles from Nbc has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.7: Fortune\n",
      "Total of 19 News Titles from Fortune has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.8: Googlenews\n",
      "Total of 95 News Titles from Googlenews has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.9: Blockchainnews\n",
      "Total of 11 News Titles from Blockchainnews has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.10: Cryptonewnset\n",
      "Total of 36 News Titles from Cryptonewsnet has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.11: Wallstreetjournal\n",
      "Total of 15 News Titles from Wallstreetjournal has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.12: Apnews\n",
      "Total of 35 News Titles from Apnews has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.13: Indepedent\n",
      "Total of 76 News Titles from Indepedent has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.14: Economictimes\n",
      "Total of 28 News Titles from Economictimes has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.15: Forbes\n",
      "Total of 24 News Titles from Forbes has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.16: Yahoo\n",
      "Total of 7 News Titles from Yahoo has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.17: The_Defiant\n",
      "Total of 25 News Titles from The_defiant has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.18: Blockchaincom\n",
      "Total of 40 News Titles from Blockchaincom has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.19: Blockchainmagazine\n",
      "Total of 18 News Titles from Blockchainmagazine has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.20: Marketwatch\n",
      "Total of 26 News Titles from Marketwatch has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.21: Washingtonpost\n",
      "Total of 20 News Titles from Washingtonpost has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.22: Techcrunch\n",
      "Total of 20 News Titles from Techcrunch has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.23: Decrypt\n",
      "Total of 33 News Titles from Decrypt has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.24: Dailymail\n",
      "Total of 79 News Titles from Dailymail has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.25: Ccn\n",
      "Total of 98 News Titles from Ccn has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.26: Newyorkpost\n",
      "Total of 25 News Titles from Newyorkpost has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.27: Guardian\n",
      "Total of 20 News Titles from Guardian has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.28: Cryptonews\n",
      "Total of 25 News Titles from Cryptonews has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.29: People\n",
      "Total of 24 News Titles from People has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.30: Coindesk\n",
      "Total of 72 News Titles from Coindesk has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.31: Blockworks\n",
      "Total of 88 News Titles from Blockworks has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.32: Financialtimes\n",
      "Total of 25 News Titles from Financialtimes has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.33: Indianexpress\n",
      "Total of 10 News Titles from Indianexpress has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.34: Cnbc\n",
      "Total of 35 News Titles from Cnbc has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.35: Timesofindia\n",
      "Total of 20 News Titles from Timesofindia has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.36: Newsnow\n",
      "Total of 25 News Titles from Newsnow has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.37: The-Blockchain\n",
      "Total of 27 News Titles from The-blockchain.com has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.38: Theconversation\n",
      "Total of 20 News Titles from Theconversation has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.39: Foxbusiness\n",
      "Total of 19 News Titles from Foxbusiness has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.40: Benzinga\n",
      "Total of 35 News Titles from Benzinga has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.41: Buzzfeed\n",
      "Total of 60 News Titles from Buzzfeed has been successfully collected!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Connecting to Site No.42: Wired\n",
      "Total of 13 News Titles from Wired has been successfully collected!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news_titles_all, news_titles_channel_specific = news_collecting()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing The News Titles\n",
    "\n",
    "Mainly takes off blank titles and blank spaces in between sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_titles = preprocess_for_vader(news_titles_all)\n",
    "\n",
    "preprocessed_channel_titles = {}\n",
    "for channel, titile in news_titles_channel_specific.items():\n",
    "    preprocessed_channel_titles[f'{channel}'] = preprocess_for_vader(titile[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Polarity Score for each channel\n",
    "\n",
    "We will be using the VADER model ... \n",
    "\n",
    "VADER's sentiment analysis provides four scores: neg (negative), neu (neutral), pos (positive), and compound. The compound score is a single metric that combines the other three scores into an overall sentiment score. Here we will take the compound core for each channel.\n",
    "\n",
    "\n",
    "VADER's compound score is calculated using a normalization formula that adjusts for the intensity of the sentiment. While the exact formula used in VADER is not publicly detailed in the original paper, it involves a sum of valence scores of each word in the lexicon, adjusted according to rules, and then normalized to range between -1 (most negative) and +1 (most positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_score_channels = {}\n",
    "for channel, titles in preprocessed_channel_titles.items():\n",
    "    polarity_score_channels[f'{channel}'] = get_summed_polarity_scores(titles)['compound']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐂 The top five sites with the most positive news sentiments 🐂 \n",
      "\n",
      "1. Timesofindia: 9.1966  \n",
      "\n",
      "2. Coindesk: 6.5571  \n",
      "\n",
      "3. Blockworks: 6.441  \n",
      "\n",
      "4. Apnews: 5.6808  \n",
      "\n",
      "5. Cointelegraph: 4.7013  \n",
      "\n",
      "___________________________________________________________________\n",
      "🐻 The top five sites with the most negative news sentiments 🐻  \n",
      "\n",
      "1. Newyorkpost: -11.1883  \n",
      "\n",
      "2. Dailymail: -10.8058  \n",
      "\n",
      "3. Nbc: -6.9758  \n",
      "\n",
      "4. Buzzfeed: -6.8161  \n",
      "\n",
      "5. Washingtonpost: -5.9181  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bullish_channles = sorted(polarity_score_channels, key=polarity_score_channels.get, reverse=True)[:5]\n",
    "\n",
    "print(f'🐂 The top five sites with the most positive news sentiments 🐂 \\n')\n",
    "for i, key in enumerate(bullish_channles):\n",
    "    print(f'{i+1}. {key}: {round(polarity_score_channels[key],4)}  \\n')\n",
    "\n",
    "print(f'___________________________________________________________________')\n",
    "print(f'🐻 The top five sites with the most negative news sentiments 🐻  \\n')\n",
    "bearish_channles = sorted(polarity_score_channels, key=polarity_score_channels.get, reverse=False)[:5]\n",
    "for i, key in enumerate(bearish_channles):\n",
    "    print(f'{i+1}. {key}: {round(polarity_score_channels[key],4)}  \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
